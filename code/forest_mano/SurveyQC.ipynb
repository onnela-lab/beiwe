{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa387b5-98a2-497b-8844-8eaaa59af236",
   "metadata": {},
   "source": [
    "### Survey QC\n",
    "\n",
    "Last updated: 04/18/2025\n",
    "\n",
    "Summary: This data pipeline was developed out of a need for accurate survey adherence statistics for the Fucito group at Yale. The overarching goal is to identify two relevant figures, N and D. N, the numerator, is the count of *valid* surveys submitted. D, the denominator, is the count of *valid* surveys delivered. Emphasis on the *valid* - this is a culmination of several rules determined through discussions between the Fucito and Beiwe teams.   \n",
    "\n",
    "Requirements: The raw survey data, including both survey answers and timings, has already been downloaded to a directory \"raw_data\" (this can be modified). Furthermore, part 3b extracts information from the Survey Settings and Interventions files (available in the 'Edit this Study' section of the dashboard), so these should be up to date. Finally, part 3c of this script calls a Beiwe API, which requires a Keyring Studies file with valid access and secret keys. \n",
    "\n",
    "#### Part 1: Identifying Mismatched Files\n",
    "\n",
    "This section iterates through raw survey data (survey answers and survey timings) and identifies files that are missing their counterparts. Survey answers record the timing of the submission in the csv file name, while survey timings have a row of data at the very end indicating that the user performed a submission action. This script records all submission times according to survey answers and separately according to suvery timings. Then these times are cross-examined to determine missing or erroneous files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9cfdf-d97b-420f-8cd6-a9017070461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below and use it to install any necessary packages.\n",
    "#%pip install ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865cd59-7743-40d2-b1f7-f04fe61f91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "import orjson\n",
    "import data_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378c21b-242b-4443-b8f4-9ebd6b0cf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_submission_rows(file_path, survey_id):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the relative file path of the file to be examined\n",
    "        survey_id: the survey of interest \n",
    "    Outputs:\n",
    "        submission_time: a list containing UTC time strings of submission times, an empty list is returned if a submission row is not found\n",
    "    Behavior:\n",
    "        This function scans each survey timings file and gradually builds up the submission histories of users \n",
    "        by appending to the existing submission_dates object each time a submission row is identified\n",
    "    '''\n",
    "    with open(file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        result = []\n",
    "        # Iterate the file by row\n",
    "        for row in reader:\n",
    "            event_value = row.get('event', '').strip().lower()\n",
    "            question_id_value = row.get('question id', '').strip().lower()\n",
    "            curr_survey_id = row.get('survey id', '').strip()\n",
    "            # Check for a submission row and return the submission time if suitable\n",
    "            if (event_value == 'submitted' or question_id_value == 'user hit submit') and curr_survey_id == survey_id:\n",
    "                result.append(row.get('UTC time'))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8d8a9-f132-45b7-abfc-752f6cf25b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_answer_files(survey_answers_dir, survey_id):\n",
    "    '''\n",
    "    Inputs:\n",
    "        survey_answers_dir: the relative file path of the survey answers directory\n",
    "        survey_id: the survey of interest \n",
    "    Outputs:\n",
    "        answers_submissions: a df containing submission times and corresponding file paths generated from answer files\n",
    "    Behavior:\n",
    "        This function iterates through all of the survey answer files in a specific survey directory and generate a df object \n",
    "        containing submission times and paths to the corresponding files\n",
    "    '''\n",
    "    answers_submissions = pd.DataFrame(columns=['Time', 'FilePath', 'Extension'])\n",
    "\n",
    "    # Check if the survey answers directory exists for specific survey id\n",
    "    survey_answers_survey_dir = os.path.join(survey_answers_dir, survey_id)\n",
    "    if os.path.isdir(survey_answers_survey_dir):\n",
    "        \n",
    "        # Iterate through survey answers files and gather their submission time via the file name\n",
    "        for file in os.listdir(survey_answers_survey_dir):\n",
    "\n",
    "            # Skip duplicates of files\n",
    "            if not re.search(r'\\+00_00\\.csv$', file):\n",
    "                # Skip if there's anything extra after +00_00\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(survey_answers_survey_dir, file)\n",
    "            submission_time = os.path.splitext(file)[0]\n",
    "            extension = os.path.splitext(file)[1]\n",
    "            new_submission = pd.DataFrame({ \n",
    "                'Time': [submission_time], \n",
    "                'FilePath': [file_path],\n",
    "                'Extension': [extension]\n",
    "            })\n",
    "            answers_submissions = pd.concat([answers_submissions, new_submission])\n",
    "            \n",
    "    # Process the 'Time' column into a standard format\n",
    "    answers_submissions['Time'] = answers_submissions['Time'].str.replace(\"_\", \":\", regex=False).str[:-6]\n",
    "    answers_submissions['Time'] = pd.to_datetime(answers_submissions['Time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Sort by 'Time' also ensuring that .csv files are prioritized\n",
    "    answers_submissions = answers_submissions.sort_values(by=[\"Time\", \"Extension\"], key=lambda col: col.map(lambda x: (x != '.csv', x)))\n",
    "    \n",
    "    return answers_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068c58a-b512-44d3-a423-3e0209f76f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_timings_files(survey_timings_dir, survey_id):\n",
    "    '''\n",
    "    Inputs:\n",
    "        survey_timings_dir: the relative file path of the survey timings directory\n",
    "        survey_id: the survey of interest \n",
    "    Outputs:\n",
    "        timings_submissions: a df containing submission times and corresponding file paths generated from timings files\n",
    "    Behavior:\n",
    "        This function iterates through all of the survey timings files in a specific survey directory and generate a df object \n",
    "        containing submission times and paths to the corresponding files\n",
    "    '''\n",
    "    timings_submissions = pd.DataFrame(columns=['Time', 'FilePath'])\n",
    "\n",
    "    # Check if the survey timings directory exists for specific survey id\n",
    "    survey_timings_survey_dir = os.path.join(survey_timings_dir, survey_id)\n",
    "    if os.path.isdir(survey_timings_survey_dir):\n",
    "            \n",
    "        # Iterate through survey timings files and call extract_submission_rows function to identify submission times\n",
    "        for file in os.listdir(survey_timings_survey_dir):\n",
    "            file_path = os.path.join(survey_timings_survey_dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                result = extract_submission_rows(file_path, survey_id)\n",
    "                if result:\n",
    "                    new_submission = pd.DataFrame({\n",
    "                        'Time': result,\n",
    "                        'FilePath': [file_path] * len(result) \n",
    "                    })\n",
    "                    timings_submissions = pd.concat([timings_submissions, new_submission]) \n",
    "\n",
    "    # Process the 'Time' column into a standard format and sort by it\n",
    "    timings_submissions['Time'] = pd.to_datetime(timings_submissions['Time'], format=\"%Y-%m-%dT%H:%M:%S.%f\").dt.floor('s')\n",
    "    timings_submissions = timings_submissions.sort_values(by=\"Time\")\n",
    "    \n",
    "    return timings_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525a342-b9ee-47fd-bd37-5e98f050c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_submission_logs(answers_submissions, timings_submissions):\n",
    "    '''\n",
    "    Inputs:\n",
    "        answers_submissions: a df containing submission times and corresponding file paths generated from answer files\n",
    "        timings_submissions: a df containing submission times and corresponding file paths generated from timings files\n",
    "    Outputs:\n",
    "        matched: a count of the number of matched files identified with the two given logs\n",
    "        unmatched: a count of the number of unmatched files identified with the two given logs\n",
    "    Behavior:\n",
    "        This function compares the answers and timings submission logs and flags any unmatched submission files\n",
    "    '''\n",
    "    # Initialize two index variables to traverse the logs and trackers of matched and unmatched files\n",
    "    answer_i = 0\n",
    "    timing_i = 0\n",
    "    matched = 0\n",
    "    unmatched = 0\n",
    "    \n",
    "    # Iterate through both lists at the same time looking for mismatches\n",
    "    while answer_i < answers_submissions.shape[0] and timing_i < timings_submissions.shape[0]:\n",
    "        time_diff = abs(answers_submissions['Time'].iloc[answer_i] - timings_submissions['Time'].iloc[timing_i])\n",
    "        # Allow an acceptable difference of 1 minute between submission times of answers and timings\n",
    "        if time_diff <= pd.Timedelta(minutes=1):\n",
    "            matched += 1\n",
    "            answer_i += 1\n",
    "            timing_i += 1\n",
    "            \n",
    "        # If differences larger than one minute are identified, there must be unmatched files\n",
    "        else:\n",
    "            if answers_submissions['Time'].iloc[answer_i] > timings_submissions['Time'].iloc[timing_i]:\n",
    "                print(f\"Unmatched file found at {timings_submissions['FilePath'].iloc[timing_i]}\")\n",
    "                unmatched += 1\n",
    "                timing_i += 1\n",
    "            else:\n",
    "                print(f\"Unmatched file found at {answers_submissions['FilePath'].iloc[answer_i]}\")\n",
    "                unmatched += 1\n",
    "                answer_i += 1\n",
    "\n",
    "    # Handle any remaining entries in either df\n",
    "    if answer_i < answers_submissions.shape[0]:\n",
    "        for index in range(answer_i, answers_submissions.shape[0]):\n",
    "            unmatched += 1\n",
    "            print(f\"Unmatched file found at {answers_submissions['FilePath'].iloc[index]}\")\n",
    "\n",
    "    if timing_i < timings_submissions.shape[0]:\n",
    "        for index in range(timing_i, timings_submissions.shape[0]):\n",
    "            unmatched += 1\n",
    "            print(f\"Unmatched file found at {timings_submissions['FilePath'].iloc[index]}\")\n",
    "\n",
    "    return matched, unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a790a-73b6-41b0-ac0a-d9ae2ab52062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_unmatched_files(base_dir):\n",
    "    '''\n",
    "    Inputs:\n",
    "        base_dir: the directory containing the raw data\n",
    "    Behavior:\n",
    "        This function runs the compare_submission_logs function on all participants and surveys to identify all unmatched files\n",
    "    '''\n",
    "    # Initialize two variables for tracking total # of matched files and # of unmatched files\n",
    "    matched = 0\n",
    "    unmatched = 0\n",
    "    \n",
    "    # Iterate through each user_id directory\n",
    "    for user_id in os.listdir(base_dir):\n",
    "        user_dir = os.path.join(base_dir, user_id)\n",
    "            \n",
    "        if os.path.isdir(user_dir):\n",
    "            # Paths to the survey_timings and survey_answers directories\n",
    "            survey_timings_dir = os.path.join(user_dir, 'survey_timings')\n",
    "            survey_answers_dir = os.path.join(user_dir, 'survey_answers')\n",
    "                \n",
    "        # Check if the survey_timings directory exists and get the survey_ids\n",
    "        if os.path.exists(survey_timings_dir):\n",
    "            survey_timings_ids = set(os.listdir(survey_timings_dir))\n",
    "    \n",
    "        # Check if the survey_answers directory exists and get the survey_ids\n",
    "        if os.path.exists(survey_answers_dir):\n",
    "            survey_answers_ids = set(os.listdir(survey_answers_dir))\n",
    "    \n",
    "        # Get the union of survey ids from survey answers and timinigs\n",
    "        all_survey_ids = survey_timings_ids | survey_answers_ids\n",
    "            \n",
    "        # Iterate through each survey_id\n",
    "        for survey_id in all_survey_ids:\n",
    "    \n",
    "            # Call the iterator functions to look through the files and extract submission times\n",
    "            answers_submissions = iterate_answer_files(survey_answers_dir, survey_id)\n",
    "            timings_submissions = iterate_timings_files(survey_timings_dir, survey_id)\n",
    "    \n",
    "            # Call the comparison function to identify any unmatched survey files\n",
    "            temp_matched, temp_unmatched = compare_submission_logs(answers_submissions, timings_submissions)\n",
    "            matched += temp_matched\n",
    "            unmatched += temp_unmatched\n",
    "            \n",
    "    print(f\"Number of matched files identified: {matched}\")\n",
    "    print(f\"Number of unmatched files identified: {unmatched}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85857c94-859b-4f7b-84ff-6cd3ec59f333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This command deletes any .ipynb_checkpoints which can interfere with file iteration\n",
    "!rm -rf $(find . -type d -name .ipynb_checkpoints)\n",
    "\n",
    "base_dir = \"raw_data\"\n",
    "identify_unmatched_files(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c98987-c463-4e55-997e-439090371587",
   "metadata": {},
   "source": [
    "#### Part 2: Identifying Duplicate Answers\n",
    "\n",
    "This section traverses through each participant's survey answers data and identifies duplicate files using MD5 hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f94fcc-7adb-4815-896c-53e0d4b3fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_file_contents(file_path):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the file path of the file to be hashed\n",
    "    Behavior:\n",
    "        This function reads a csv file and hashed it into a 32 character string that can help identify duplicates\n",
    "    '''\n",
    "    import hashlib\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as file:\n",
    "        buf = file.read()\n",
    "        hasher.update(buf)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def identify_duplicate_answers (base_dir, target_survey_id=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        base_dir: the name of the directory containing the raw data\n",
    "        target_survey_id: the survey ID to check for duplicate answers, if None it checks all surveys.\n",
    "    Behavior:\n",
    "        This function compares all the survey answer files of a specified survey within each participant and identifies any duplicates\n",
    "    '''\n",
    "\n",
    "    # Initialize a dictionary to store all hashes\n",
    "    all_hashes = {}\n",
    "    \n",
    "    # Iterate through each user_id directory\n",
    "    for user_id in os.listdir(base_dir):\n",
    "        user_dir = os.path.join(base_dir, user_id)\n",
    "        \n",
    "        if os.path.isdir(user_dir):\n",
    "            # Path to the survey_answers directory\n",
    "            survey_answers_dir = os.path.join(user_dir, 'survey_answers')\n",
    "            \n",
    "            # Check if the survey_answers directory exists\n",
    "            if os.path.exists(survey_answers_dir):\n",
    "                # Get the survey_ids to check\n",
    "                if target_survey_id:\n",
    "                    survey_ids_to_check = [target_survey_id]\n",
    "                else:\n",
    "                    survey_ids_to_check = os.listdir(survey_answers_dir)\n",
    "                \n",
    "                # Iterate through each survey_id\n",
    "                for survey_id in survey_ids_to_check:\n",
    "                    # Path to the specific survey_id directory\n",
    "                    survey_answers_survey_dir = os.path.join(survey_answers_dir, survey_id)\n",
    "                    \n",
    "                    if os.path.isdir(survey_answers_survey_dir):\n",
    "                        # Gather all .csv file paths in the directory\n",
    "                        file_paths = [\n",
    "                            os.path.join(survey_answers_survey_dir, file)\n",
    "                            for file in os.listdir(survey_answers_survey_dir)\n",
    "                            if os.path.isfile(os.path.join(survey_answers_survey_dir, file)) and file.endswith('.csv')\n",
    "                        ]\n",
    "                        \n",
    "                        # Maintain a dictionary to track duplicates\n",
    "                        for file_path in file_paths:\n",
    "                            # Generate hash of the file contents\n",
    "                            file_hash = hash_file_contents(file_path)\n",
    "                            if file_hash in all_hashes:\n",
    "                                all_hashes[file_hash].append(file_path)\n",
    "                            else:\n",
    "                                all_hashes[file_hash] = [file_path]\n",
    "\n",
    "    duplicates_output = []\n",
    "    \n",
    "    # Prepare duplicate groups for output\n",
    "    for file_group in all_hashes.values():\n",
    "        if len(file_group) > 1:\n",
    "            joined_paths = \"\\n\".join(file_group)\n",
    "            # Print duplicates to the console\n",
    "            print(f\"Duplicate files found:\\n{joined_paths}\\n\")\n",
    "            duplicates_output.append(f\"Duplicate files found:\\n{joined_paths}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4586f-020b-41dd-a9eb-df57e50b0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_duplicate_answers(base_dir, target_survey_id=\"PmZQCMHU8cAhIdZshFuipCPi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666eb8f0-d430-4a78-ab90-12dc039fe0ab",
   "metadata": {},
   "source": [
    "#### Part 3: Identifying Unexpected Submissions\n",
    "\n",
    "This section of the script attempts to flag any instances of *unexpected* survey submissions. There are two categories of submissions that have been deemed *unexpected*: multiple submissions for any 24-hour period$^1$, and submissions outside of the designated survey periods. \n",
    "\n",
    "$^1$Eligible submission periods may be less than 24 hours based on the deployment of the next survey iteration.\n",
    "\n",
    "##### Part 3a: Generating a Log of Answers\n",
    "\n",
    "The first task is to generate a log of all survey answers for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c2682-b1ae-4d30-a191-7ee8425fe675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers_log(base_dir, survey_id=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        base_dir: the directory containing the raw data\n",
    "        survey_id: the survey_id to be filtered, if none is specified, all surveys are considered\n",
    "    Output:\n",
    "        full_log: the df object containing all submission dates and filepaths for each user\n",
    "    Behavior:\n",
    "        This function iterates through all users and generates one large object filled with \n",
    "        information about participants' survey answer times\n",
    "    '''\n",
    "    # Generate a df object to hold all submission times for participants\n",
    "    full_log = pd.DataFrame(columns=['BeiweID', 'Date', 'TimestampUTC', 'FilePath'])\n",
    "\n",
    "    # Iterate through each user_id directory\n",
    "    for user_id in os.listdir(base_dir):\n",
    "        user_dir = os.path.join(base_dir, user_id)\n",
    "            \n",
    "        if os.path.isdir(user_dir):\n",
    "            # Paths to the survey_answers directorie\n",
    "            survey_answers_dir = os.path.join(user_dir, 'survey_answers')\n",
    "    \n",
    "        # Check if the survey_answers directory exists and get the survey_ids\n",
    "        if os.path.exists(survey_answers_dir):\n",
    "            survey_answers_ids = set(os.listdir(survey_answers_dir))\n",
    "\n",
    "        # Only consider specified survey_id\n",
    "        if survey_id is not None:\n",
    "    \n",
    "            # Call the iterator functions to look through the files and extract submission times\n",
    "            answers_submissions = iterate_answer_files(survey_answers_dir, survey_id)\n",
    "            answers_submissions = answers_submissions[answers_submissions['Extension'] == \".csv\"]\n",
    "\n",
    "            # Add the new submissions to the existing log\n",
    "            new_submission = pd.DataFrame({\n",
    "                'BeiweID': [user_id] * len(answers_submissions),\n",
    "                'Date': answers_submissions['Time'].dt.date,\n",
    "                'TimestampUTC': answers_submissions['Time'],\n",
    "                'FilePath': answers_submissions['FilePath']\n",
    "            })\n",
    "            full_log = pd.concat([full_log, new_submission]) \n",
    "        \n",
    "        else:\n",
    "            # Iterate through each survey\n",
    "            for survey in survey_answers_ids:\n",
    "\n",
    "                # Call the iterator functions to look through the files and extract submission times\n",
    "                answers_submissions = iterate_answer_files(survey_answers_dir, survey)\n",
    "                answers_submissions = answers_submissions[answers_submissions['Extension'] == \".csv\"]\n",
    "\n",
    "                # Add the new submissions to the existing log\n",
    "                new_submission = pd.DataFrame({\n",
    "                    'BeiweID': [user_id] * len(answers_submissions),\n",
    "                    'Date': answers_submissions['Time'].dt.date,\n",
    "                    'TimestampUTC': answers_submissions['Time'],\n",
    "                    'FilePath': answers_submissions['FilePath']\n",
    "                })\n",
    "                full_log = pd.concat([full_log, new_submission])\n",
    "                \n",
    "    full_log = full_log.sort_values(by=[\"BeiweID\", \"TimestampUTC\"])\n",
    "    return full_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c049b-a01e-4559-9ac5-b81233561ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $(find . -type f -name .DS_Store)\n",
    "base_dir = \"raw_data\"\n",
    "log = generate_answers_log(base_dir, survey_id=\"PmZQCMHU8cAhIdZshFuipCPi\")\n",
    "log.to_csv('answers_log_full.csv', index=False)\n",
    "\n",
    "# Generate a csv containing Beiwe IDs and their survey submission counts\n",
    "counts = log.groupby('BeiweID').size()\n",
    "counts = counts.reset_index(name='SurveyCount')\n",
    "counts.to_csv('final_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29a619-2ada-4b46-a909-e0c84844d8d8",
   "metadata": {},
   "source": [
    "##### Part 3b: Generating an Expected Schedule\n",
    "\n",
    "Next, we need to generate an expected schedule of diary notifications based on participants' enrollment dates and the diary relative schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34610f29-0c3a-446d-8062-a0f27bd61440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_interventions_file(file_path):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the path to the interventions json\n",
    "    Output:\n",
    "        enrollment_log: the df object containing every participant's enrollement date\n",
    "    Behavior:\n",
    "        This function looks through the interventions json to determine enrollment dates for all participants. \n",
    "        THIS FUNCTION NEEDS TO BE CUSTOMIZED TO A SPECIFIC STUDY.\n",
    "    '''\n",
    "    # Initialize an empty list to hold user data\n",
    "    enrollment_log = []\n",
    "\n",
    "    # Read the interventions json file\n",
    "    with open(file_path, 'r') as file:\n",
    "        interventions = json.load(file)\n",
    "        # Iterate for each individual\n",
    "        for user in interventions:\n",
    "            user_data = interventions[user]\n",
    "            key = next(iter(user_data.keys()))\n",
    "            # Record the Beiwe ID and enrollment date of the individual\n",
    "            enrollment_log.append({\n",
    "                'BeiweID': user,\n",
    "                'EnrollmentDate': user_data[key]['Enrollment date']\n",
    "            })\n",
    "    return pd.DataFrame(enrollment_log)\n",
    "\n",
    "def read_settings_file(file_path):\n",
    "    '''\n",
    "    Inputs:\n",
    "        file_path: the path to the settings json\n",
    "    Output:\n",
    "        notification_days: a list containing the relative deployment dates from the enrollment date\n",
    "    Behavior:\n",
    "        This function looks through the settings json to determine which relative dates the diary survey is deployed on.\n",
    "        THIS FUNCTION NEEDS TO BE CUSTOMIZED TO A SPECIFIC STUDY.\n",
    "    '''\n",
    "    # Initialize an empty list to hold user data\n",
    "    notification_days = []\n",
    "\n",
    "    # Read the settings json file\n",
    "    with open(file_path, 'r') as file:\n",
    "        settings = json.load(file)\n",
    "        # Access the relative schedule of the Diary survey\n",
    "        timings = settings['surveys'][6]['relative_timings']\n",
    "        for timing in timings:\n",
    "            # Record the relative deployment day of the survey\n",
    "            notification_days.append(timing[1])\n",
    "\n",
    "    notification_days.sort()\n",
    "    return notification_days\n",
    "\n",
    "def generate_expected_survey_schedule():\n",
    "    '''\n",
    "    Output:\n",
    "        full_schedule: the df object containing all expected notification dates for all participants\n",
    "    Behavior:\n",
    "        This function calls the two methods above to look through study jsons and then generates an \n",
    "        expected survey schedule for each participant\n",
    "    '''\n",
    "    # Gather enrollment data from the intervention file\n",
    "    interventions_file = \"m4z54N5SU7Eqq2LbwmxQd2UN_intervention_data.json\"\n",
    "    interventions = read_interventions_file(interventions_file)\n",
    "\n",
    "    # Gather scheduling data using the settings file\n",
    "    settings_file = \"Yale_Fucito_Young_Adult_Alcohol_-_Live_Study_surveys_and_settings.json\"\n",
    "    settings = read_settings_file(settings_file)\n",
    "\n",
    "    # Initiate a new list to track the full expected schedule of surveys for all participants\n",
    "    full_schedule = []\n",
    "    # Iterate for each pariticipant\n",
    "    for index, row in interventions.iterrows():\n",
    "        # Extract the Beiwe ID and enrollment date\n",
    "        enrollment_date = pd.Timestamp(row['EnrollmentDate'])\n",
    "        beiwe_id = row['BeiweID']\n",
    "\n",
    "        # Iterate for each deployment day of the Diary relative schedule\n",
    "        for day in settings:\n",
    "            # Calculate the absolute date of the deployment\n",
    "            new_date = enrollment_date + timedelta(days=day)\n",
    "            burst = day // 90 + 1\n",
    "            # Record this absolute date\n",
    "            full_schedule.append({\n",
    "                'BeiweID': beiwe_id,\n",
    "                'EnrollmentDate': enrollment_date,\n",
    "                'RelativeDay': day,\n",
    "                'Burst': burst,\n",
    "                'CalculatedDate': new_date\n",
    "            })\n",
    "            \n",
    "    full_schedule = pd.DataFrame(full_schedule)\n",
    "    full_schedule = full_schedule.sort_values(by=[\"BeiweID\", \"RelativeDay\"])\n",
    "    return full_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f05fe-07fb-4187-a34a-5797c66b88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_expected_survey_schedule()\n",
    "dates.to_csv('notification_dates_log.csv', index=False)\n",
    "\n",
    "# Update final counts csv with enrollment dates and final survey dates\n",
    "counts = pd.read_csv(\"final_counts.csv\")\n",
    "last_dates = dates.groupby('BeiweID').last().reset_index()\n",
    "counts = counts.merge(\n",
    "            last_dates[['BeiweID', 'EnrollmentDate', 'CalculatedDate']],\n",
    "            how='left',\n",
    "            left_on=['BeiweID'],\n",
    "            right_on=['BeiweID']\n",
    "        )\n",
    "counts.rename(columns={'CalculatedDate': 'LastSurvey'}, inplace=True)\n",
    "counts.to_csv('final_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a4dc3-3d3f-4809-905e-ae773071369c",
   "metadata": {},
   "source": [
    "##### Part 3c: Extracting Notification Times\n",
    "\n",
    "Using the notification API we can determine the absolute timings of survey notifications (which is important because deployments are localized to the participant's timezone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76762ab2-6097-4287-b711-2e6597a62052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_notifications_api(beiwe_id, access_key, secret_key):\n",
    "    '''\n",
    "    Inputs:\n",
    "        beiwe_id: the user whose notification history to access\n",
    "        access_key: API access key from the keyring file\n",
    "        secret_key: API secret key from the keyring file \n",
    "    Output:\n",
    "        notification_history: a df containing the participant's notification deployment history for the Diary survey\n",
    "    Behavior:\n",
    "        This function calls the notification API to get a specific participant's notification history.\n",
    "        The API object is then converted into a df and filtered for original deployments of Diary surveys.\n",
    "    '''\n",
    "\n",
    "    # Make a post request to the get-participant-notification-history/v1 endpoint, including the api key,\n",
    "    # secret key, and participant_id as post parameters.\n",
    "    endpoint = \"https://studies.beiwe.org/get-participant-notification-history/v1\"\n",
    "    t_start = datetime.now()\n",
    "    print(\"Starting request at\", t_start, flush=True)\n",
    "    response = requests.post(\n",
    "        endpoint,\n",
    "        \n",
    "        # refine your parameters here\n",
    "        data={\n",
    "            \"participant_id\": beiwe_id,\n",
    "            \"access_key\": access_key,\n",
    "            \"secret_key\": secret_key           \n",
    "        },\n",
    "        allow_redirects=False,\n",
    "    )\n",
    "    t_end = datetime.now()\n",
    "    print(\"Request completed at\", t_end.isoformat(), \"duration:\", (t_end - t_start).total_seconds(), \"seconds\")\n",
    "    \n",
    "    status_code = response.status_code\n",
    "    raw_output = response.content\n",
    "    \n",
    "    # Sanity checking to make sure the request worked\n",
    "    print(\"http status code:\", response.status_code)\n",
    "    \n",
    "    assert status_code != 400, \\\n",
    "        \"400 usually means you are missing a required parameter, or something critical isn't passing some checks.\\n\" \\\n",
    "        \"Check your access key and secret key, if there is a study id make sure it is 24 characters long.\"\n",
    "    \n",
    "    assert status_code != 403, \\\n",
    "        \"Permissions Error, you are not authenticated to view data on this study.\"\n",
    "    \n",
    "    assert status_code != 404, \\\n",
    "        \"404 means that the entity you have specified does not exist. Check details like study_id, patient_id, etc.\"\n",
    "    \n",
    "    assert response.status_code != 301, \\\n",
    "        \"Encountered HTTP redirect, you may have forgotten the s in https. first 100 bytes of response:\\n\" \\\n",
    "        f\"{raw_output[:100]}\"\n",
    "    \n",
    "    assert response.content != b\"\", \"No data was returned by the server...\"\n",
    "    \n",
    "    print(\"Testing whether it is valid json...\")\n",
    "    try:\n",
    "        json_response = orjson.loads(response.content)\n",
    "        print(\"JSON successfully loadded into variable `json_response`\")\n",
    "    except orjson.JSONDecodeError:\n",
    "        print(\"Not valid JSON - which may or may not be an issue! Here is the raw output of the first 100 bytes:\")\n",
    "        print(raw_output[:100])\n",
    "        json_response = None\n",
    "\n",
    "    try:\n",
    "        # Filter out notifications for non-Diary surveys and resends/non-relative deployments\n",
    "        notifications_data = json_normalize(json_response['PmZQCMHU8cAhIdZshFuipCPi'])\n",
    "        notifications_data = notifications_data[(notifications_data['type'] == 'relative') & (~notifications_data['resend'])]\n",
    "        \n",
    "        # Create new columns for Beiwe ID, the date and the UTC time of delivery\n",
    "        notifications_data['id'] = beiwe_id\n",
    "        notifications_data['date'] = notifications_data['scheduled_time'].apply(lambda x: x.split('T')[0])\n",
    "        notifications_data['timestamp_UTC'] = notifications_data['timestamp'].apply(lambda x: pd.to_datetime(x, utc=True))\n",
    "        notifications_data['timestamp_UTC'] = notifications_data['timestamp_UTC'].dt.tz_convert(None)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {str(e)} - The expected key wasn't found in the API response.\")\n",
    "        return pd.DataFrame(columns=['id','date', 'timestamp_UTC'])\n",
    "    return notifications_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fbe9b-bd11-4a27-9577-e43c0dc95183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_notifications_to_schedule(notification_dates_file):\n",
    "    '''\n",
    "    Inputs:\n",
    "        notification_dates_file: the csv file containing the expected notification schedule, as generated in Part 3b\n",
    "    Output:\n",
    "        notification_log: a df containing everything in the notification_dates_file with added columns for \n",
    "        delivery times and truncation times (end of that deployment's eligible submission period)\n",
    "    Behavior:\n",
    "        This function adds information about delivery times from the notification API to the notification schedule file\n",
    "    '''\n",
    "    # Read the notification_dates_file, convert it into a df and initialize new columns\n",
    "    schedule = pd.read_csv(notification_dates_file)\n",
    "    schedule['timestamp_UTC'] = None\n",
    "    \n",
    "    # Extract the unique users from this file\n",
    "    users = schedule['BeiweID'].unique()\n",
    "    \n",
    "    # Read the keyring_studies file to get the API access and secret keys\n",
    "    kr = data_summaries.read_keyring(\"keyring_studies.py\")\n",
    "    access_key = kr.get(\"ACCESS_KEY\")\n",
    "    secret_key = kr.get(\"SECRET_KEY\")\n",
    "\n",
    "    # Iterate for all users\n",
    "    for user in users:\n",
    "        # Collect the user's notification history\n",
    "        notifications_data = call_notifications_api(user, access_key, secret_key)\n",
    "\n",
    "        # Update the schedule df with the notification history\n",
    "        updated_schedule = schedule.merge(\n",
    "            notifications_data[['id','date', 'timestamp_UTC']],\n",
    "            how='left',\n",
    "            left_on=['BeiweID','CalculatedDate'],\n",
    "            right_on=['id','date']\n",
    "        )\n",
    "        schedule.loc[schedule['BeiweID'] == user, 'timestamp_UTC'] = updated_schedule['timestamp_UTC_y']\n",
    "\n",
    "    # Rename the timestamp column and add a column for the end of the survey's eligible period \n",
    "    schedule = schedule.rename(columns={'timestamp_UTC': 'DeliveredUTC'})\n",
    "    schedule['TruncatedUTC'] = schedule['DeliveredUTC'] + timedelta(hours=24)\n",
    "\n",
    "    for i in range(len(schedule) - 1):  \n",
    "        if schedule['BeiweID'].iloc[i] == schedule['BeiweID'].iloc[i + 1]:\n",
    "            current_truncated = schedule['TruncatedUTC'].iloc[i]\n",
    "            next_delivered = schedule['DeliveredUTC'].iloc[i + 1]\n",
    "            \n",
    "            if pd.notna(current_truncated) and pd.notna(next_delivered):\n",
    "                schedule.at[schedule.index[i], 'TruncatedUTC'] = min(current_truncated, next_delivered)\n",
    "\n",
    "    return schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5becabb7-c1f5-47c2-8032-9eb01d745cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schedule = match_notifications_to_schedule(\"notification_dates_log.csv\")\n",
    "schedule.to_csv(\"notification_dates_log_with_deliveries.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc9895-4253-4639-8b1e-7642933696e5",
   "metadata": {},
   "source": [
    "##### Part 3d: Identify Unexpected Submissions\n",
    "\n",
    "Finally, we can cross-reference the submissions log against the notifications log to find two kinds of unexpected surveys as mentioned above:\n",
    "1. Submissions outside of the expected schedules\n",
    "2. Multiple submissions in one notification period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28e81f-b3c4-4d2a-8c2a-ed54410dec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_answers_to_notifications(notifications_file, answers_file, counts_file):\n",
    "    '''\n",
    "    Inputs:\n",
    "        notifications_file: the csv file containing the expected and delivered notification schedule, as generated in Parts 3b/3c\n",
    "        answers_file: the csv file containing the answer submission log, as generated in Part 3a\n",
    "        counts_file: the csv file containing the submission counts for each participant\n",
    "    Output:\n",
    "        notification_log: a df containing everything in the notification_dates_file_with_deliveries with an additional\n",
    "        column for number of submissions within each notification window\n",
    "        counts: a df that adds counts of outside and double submissions to the counts file\n",
    "    Behavior:\n",
    "        This function cross-checks the two input logs and flags any unexpected submissions\n",
    "    '''\n",
    "    # Read the notification log csv\n",
    "    schedule = pd.read_csv(notifications_file)\n",
    "    schedule['DeliveredUTC'] = schedule['DeliveredUTC'].apply(lambda x: pd.to_datetime(x))\n",
    "    schedule['TruncatedUTC'] = schedule['TruncatedUTC'].apply(lambda x: pd.to_datetime(x))\n",
    "    schedule['SurveysSubmitted'] = 0\n",
    "\n",
    "    # Read the answers log csv\n",
    "    answers = pd.read_csv(answers_file)\n",
    "\n",
    "    # Read the final counts csv\n",
    "    counts = pd.read_csv(counts_file)\n",
    "    counts[\"DoubleSubmissions\"] = 0\n",
    "    counts[\"OutsideSubmissions\"] = 0\n",
    "    counts[\"CheckManually\"] = False\n",
    "\n",
    "    # Create a list for the filtered answers log\n",
    "    filtered_answers = []\n",
    "\n",
    "    outside, extra = 0,0\n",
    "\n",
    "    # Iterate each row of the answers log\n",
    "    for index, row in answers.iterrows():\n",
    "        # Extract the Beiwe ID, timestamp and file path\n",
    "        timestamp = pd.Timestamp(row['TimestampUTC'])\n",
    "        date = row['Date']\n",
    "        beiwe_id = row['BeiweID']\n",
    "        file_path = row['FilePath']\n",
    "\n",
    "        # Look for notification delibery corresponding to the answer submission\n",
    "        mask = (\n",
    "            (schedule['BeiweID'] == beiwe_id) &\n",
    "            (schedule['DeliveredUTC'] < timestamp) & \n",
    "            (schedule['TruncatedUTC'] > timestamp)\n",
    "        )\n",
    "\n",
    "        # Indicator whether this is a valid row\n",
    "        valid_row = True\n",
    "        \n",
    "        if schedule.loc[mask].empty:\n",
    "            if not schedule.loc[(schedule['BeiweID'] == beiwe_id) & (schedule['CalculatedDate'] == date)].empty:\n",
    "                counts.loc[counts['BeiweID'] == beiwe_id, 'CheckManually'] = True\n",
    "                print(f\"[CHECK MANUALLY] Issue with notification history: {file_path}\")\n",
    "            else:\n",
    "                counts.loc[counts['BeiweID'] == beiwe_id, 'OutsideSubmissions'] += 1\n",
    "                print(f\"Submission outside of diary period: {file_path}\")\n",
    "            outside += 1\n",
    "        else:\n",
    "            burst = schedule.loc[mask, 'Burst'].iloc[0]\n",
    "            \n",
    "        schedule.loc[mask, 'SurveysSubmitted'] = schedule.loc[mask, 'SurveysSubmitted'] + 1\n",
    "\n",
    "        if (schedule.loc[mask, 'SurveysSubmitted'] > 1).any():\n",
    "            valid_row = False\n",
    "            counts.loc[counts['BeiweID'] == beiwe_id, 'DoubleSubmissions'] += 1\n",
    "            print(f\"Unexpected extra submission: {file_path}\")\n",
    "            extra += 1\n",
    "\n",
    "        if valid_row:\n",
    "            row['Burst'] = burst\n",
    "            filtered_answers.append(row)\n",
    "\n",
    "    print(f\"Total submissions outside of diary periods: {outside}\")\n",
    "    print(f\"Total submission periods (days) with multiple submissions: {extra}\")\n",
    "    filtered_answers = pd.DataFrame(filtered_answers, columns=['BeiweID','Date','TimestampUTC','FilePath','Burst'])\n",
    "    return schedule, counts, filtered_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70459319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_notification_deliveries(notifications_file, counts):\n",
    "    '''\n",
    "    Inputs:\n",
    "        notifications_file: the csv file containing the expected and delivered notification schedule, as generated in Parts 3b/3c\n",
    "        counts_file: the submission counts for each participant\n",
    "    Output:\n",
    "        counts: a df that adds counts of total and valid notification deliveries to the counts file\n",
    "    Behavior:\n",
    "        This function counts the total and valid notification deliveries for each participant\n",
    "    '''\n",
    "    # Read the notification log csv\n",
    "    schedule = pd.read_csv(notifications_file)\n",
    "    schedule['DeliveredUTC'] = schedule['DeliveredUTC'].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "    # Read add some columns to the counts df\n",
    "    counts[\"TotalDeliveredCount\"] = 0\n",
    "    counts[\"InvalidDeliveredCount\"] = 0\n",
    "    for index, row in schedule.iterrows():\n",
    "        # Extract the Beiwe ID, timestamp and date\n",
    "        delivered_utc = pd.Timestamp(row['DeliveredUTC'])\n",
    "        delivered_date = delivered_utc.date()\n",
    "        calculated_date = pd.Timestamp(row['CalculatedDate']).date()\n",
    "        beiwe_id = row['BeiweID']\n",
    "\n",
    "        # Check if the participant is in the counts file\n",
    "        if beiwe_id in counts['BeiweID'].values:\n",
    "\n",
    "            # Check if the delivered utc field is not null\n",
    "            if pd.notna(delivered_utc):\n",
    "\n",
    "                # Increment the total delivered count\n",
    "                counts.loc[counts['BeiweID'] == beiwe_id, 'TotalDeliveredCount'] += 1\n",
    "\n",
    "                # Check if the delivered date is the same as the calculated date\n",
    "                if abs((delivered_date - calculated_date).days) > 1:\n",
    "\n",
    "                    # Increment the valid delivered count\n",
    "                    counts.loc[counts['BeiweID'] == beiwe_id, 'InvalidDeliveredCount'] += 1\n",
    "\n",
    "    counts['NumeratorEstimate'] = counts['SurveyCount'] - counts['DoubleSubmissions'] - counts['OutsideSubmissions']\n",
    "    counts['DenominatorEstimate'] = counts['TotalDeliveredCount'] - counts['InvalidDeliveredCount']\n",
    "    counts['Adherence%Estimate'] = ((counts['NumeratorEstimate'] / counts['DenominatorEstimate']) * 100).round(3)            \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42c4aa-da61-4de5-9563-52ee454dd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "notifications_file = \"notification_dates_log_with_deliveries.csv\"\n",
    "answers_file = \"answers_log_full.csv\"\n",
    "counts_file = \"final_counts.csv\"\n",
    "schedule, counts, answers = match_answers_to_notifications(notifications_file, answers_file, counts_file)\n",
    "# Update the notification log with the submission counts\n",
    "schedule.to_csv(\"notification_dates_log_with_deliveries_and_submissions.csv\", index = False)\n",
    "\n",
    "# Save an answer logs containing only the valid submissions\n",
    "answers = answers[['BeiweID','Date','Burst','TimestampUTC','FilePath']]\n",
    "answers.to_csv(\"answers_log_filtered.csv\", index = False)\n",
    "\n",
    "# Update the counts file with the total and valid notification deliveries\n",
    "counts = count_notification_deliveries(notifications_file, counts)\n",
    "\n",
    "# Update final counts \n",
    "counts = counts.sort_values(by=['LastSurvey', 'BeiweID'])\n",
    "counts = counts[\n",
    "    ['BeiweID',\n",
    "     'EnrollmentDate',\n",
    "     'LastSurvey',\n",
    "     'SurveyCount',\n",
    "     'DoubleSubmissions',\n",
    "     'OutsideSubmissions', \n",
    "     'CheckManually', \n",
    "     'TotalDeliveredCount', \n",
    "     'InvalidDeliveredCount', \n",
    "     'NumeratorEstimate', \n",
    "     'DenominatorEstimate', \n",
    "     'Adherence%Estimate'\n",
    "     ]\n",
    "]\n",
    "counts.to_csv(\"final_counts.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
